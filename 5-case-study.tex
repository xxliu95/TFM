\chapter{Simulations and Results}
\label{chap:scenarios} 

This chapter will test the adaptation algorithms implemented in the \textit{ABR}
module from the \autoref{chap:abrmodule} in various simulated scenarios. The \autoref{sec:metrics}
will present the metrics used for the comparisons. The \autoref{sec:scenarios} will 
go through all the simulation scripts and its results. The \autoref{sec:fairness} will
analyse the fairness of the adaptation algorithms. Finally, the \autoref{sec:simconclu},
will discuss the conclusions and limitations of the \textit{ABR} module.

% \section{Introduction}

\section{Comparison Metrics}
\label{sec:metrics}

For the comparison, the metrics introduced in the \autoref{sec:qoemetrics} will be used.
In addition, other metrics will be used that may also be of interest. And they are as follows:

\begin{itemize}[topsep=0pt, noitemsep]
    \item \textbf{Average Throughput}. The average of the network throughput.
    \item \textbf{Playback start time}. The time the client takes to start the playback.
    \item \textbf{Total time watched}. Total time watched by the client.
    \item \textbf{Quality switches}. The number of times the representation changed.
    \item \textbf{Paused times}. The number of times the playback paused.
    \item \textbf{Time at each quality}. The time spent at each quality.
    \item \textbf{Buffer status}. The buffer status in milliseconds of content as a function of time.
    \item \textbf{QoE Score}. This is a score based on various metrics, the formula is as follows:
    \begin{equation}
        QoE\ score = \frac{t_w-pb_s-\sum_{i=1}^{M} \frac{t_i}{2}\cdot (\frac{1}{2}-\frac{i+1}{M})-\frac{1}{2}\cdot (qs+pt)}{simulation\ time}
    \end{equation}
    with
    \begin{itemize}[topsep=0pt, noitemsep]
        \item[$\circ$] $t_w$ 		                            Time watched
        \item[$\circ$] $pb_s$ 		                            Playback start time
        \item[$\circ$] $t_i\ _{q=\{0,1,...,M\}}$ 		        Time at each quality 
        \item[$\circ$] $qs$ 		                            Quality switches
        \item[$\circ$] $pt$ 		                            Paused times
    \end{itemize}
\end{itemize}

% \section{Example script}
% \label{sec:example}


\section{Scenarios}
\label{sec:scenarios}

In the next sections, the throughput rule of \textit{dash.js} will be refered as \textit{DASH throughput},
the BOLA rule as \textit{BOLA}, the bandwidth estimation of \textit{hls.js} as \textit{HLS} and the combination
of the BOLA and the throughput rule of \textit{dash.js} simply as \textit{DASH}.

\subsection{Scenario 1}
This section will take a look a basic network scenario. To be as simply as possible, the will be 
only two nodes linked with a \texttt{PointToPoint} connection. The simulation time is 50 seconds 
and the datarate will vary in time. In this scenario, seven bitrates are used.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/s1c1.pdf}
    \caption{Scenario 1. Quality vs time}
    \label{fig:s1c1}
\end{figure}

By looking at the \autoref{fig:s1c1}, the first thing noticeable is that the \textit{HLS} and the \textit{DASH throughput}'s
quality functions are almost the same. \textit{BOLA} reached a little bit earier to the quality index 5 and 
sustained a good overall performance.
The combination of both rules in \textit{DASH} seems to work pretty nicely, with one exception of going
down to quality index 2 almost at the end of the simulation. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/s1c2.pdf}
    \caption{Scenario 1. CDF quality}
    \label{fig:s1c2}
\end{figure}

The \autoref{fig:s1c2} show a \textit{Cumulative Distribution Function (CDF)}. In this 
case, the \textit{CDF} shows the video quality choice statistics in the form of percentages. 
Both \textit{HLS} and \textit{DASH throughput} obteined a higher quality during most of 
the simulation time and never played segments from the lowest quality.

\subsection{Scenario 2}

\subsubsection{Scenario 2.1}

Standing still

\subsubsection{Scenario 2.2}

Moving away

50 moving 20m/s

\subsubsection{Scenario 2.3}

Moving towards

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/s2c1.pdf}
    \caption{Scenario 2. Buffer Status}
    \label{fig:s2c1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/s2c2_1.pdf}
\end{figure}

\begin{figure}[h]
    \centering    
    \includegraphics[width=\textwidth]{img/s2c2_2.pdf}
    \caption{Scenario 2. Throughput}
    \label{fig:s2c2}
\end{figure}


\begin{table}[]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
                              & Non-Moving & Moving Away & Moving Towards \\ \midrule
    QoE Score                 & 0.812078   & 0.535326    & 0.701826       \\
    Average throughput (Mbps) & 23.0487    & 8.1720      & 12.7028        \\
    Time watched (s)          & 48.9       & 38.0        & 48.485         \\
    Quality switches          & 7          & 12          & 13             \\ \bottomrule
    \end{tabular}
    \caption{Scenario 2. Metrics Comparison}
\end{table}



\subsection{Scenario 3}

This section will analysis a lte scenario. There will be six UEs watching video at the same time.
three of them have stationary and the remaining three are randomly moving.
In this scenario, fifteen bitrates are used.

The scenario has one \textit{eNodeB}, with one antenna. An there is also a building. The 
\autoref{fig:s3i1} shows a radio enviroment map of the scenario.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/s3i1.pdf}
    \caption{Scenario 3. Radio Environment Map}
    \label{fig:s3i1}
\end{figure}

\begin{table}[]
    \begin{tabular}{@{}llrrrr@{}}
    \toprule
                               &         & \multicolumn{1}{l}{BOLA} & \multicolumn{1}{l}{DASH} & \multicolumn{1}{l}{DASH throughpu} & \multicolumn{1}{l}{HLS} \\ \midrule
    \multirow{3}{*}{QoE Score} & Average & 0.3222501667             & 0.3389108333             & 0.3891433333                       & 0.3908161667            \\
                               & Max     & 0.47895                  & 0.568955                 & 0.621531                           & 0.631055                \\
                               & Min     & 0.245517                 & 0.245722                 & 0.220542                           & 0.231055                \\ \cmidrule(l){2-6} 
    \end{tabular}
    \caption{Scenerio 3. QoE Score}
\end{table}

\subsection{Scenario 4}

\subsubsection{Jain Fairness Index}

Fairness metrics are used to determine whether the adaptation 
algorithm is able to deliver an equitable share of the network bandwidth 
to different clients. In this analysis, the \textit{Jain Fairness Index (JFI)}
\cite{jfi} is used. The \textit{JFI} is calculated by this formula:

\begin{equation}
    JFI=\frac{\bigg(\sum\limits_{c\in C}\bar{B}\bigg)^2}{\left | C \right |\sum\limits_{c\in C}(\bar{B})^2}
\end{equation}

where  $C$ are the Clients and $\bar{B}$ are the Average Throughputs

\begin{table}[]
    \centering
    \begin{tabular}{@{}lrrrr@{}}
    \toprule
        & \multicolumn{1}{l}{BOLA} & \multicolumn{1}{l}{DASH} & \multicolumn{1}{l}{DASH throughput} & \multicolumn{1}{l}{HLS} \\ \midrule
    JFI & \textbf{0.972185193}     & 0.9716453768             & 0.9271291449                        & 0.929252551             \\
    MAX & 10289.8                  & 10289.8                  & 19953.9                             & \textbf{20006.4}        \\ \bottomrule
    \end{tabular}
    \caption{Scenerio 4. Fairness Comparison}
\end{table}

\section{Conclusions}
\label{sec:simconclu}

limitations